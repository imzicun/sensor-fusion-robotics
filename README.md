# Sensor Fusion for Robotics  
### Comparing Complementary and Kalman Filters for Orientation Estimation

This project implements and compares two sensor fusion techniques â€“ a **Complementary Filter** and a **Kalman Filter** â€“ to estimate the orientation of a robot using noisy measurements from simulated sensors (gyro, accelerometer, and optionally wheel encoder).  

The goal is to demonstrate how sensor fusion improves state estimation under noise, drift, and uncertainty â€” a key skill in robotics, mechatronics, and embedded systems.

---

## ðŸš€ Overview

Robots rely on multiple imperfect sensors to estimate their orientation.  
In this project:

- **Gyroscope** gives angular velocity (good short-term, but drifts)
- **Accelerometer** gives absolute angle (very noisy)
- **Encoder** gives an additional velocity estimate (optional)
- **Complementary Filter** blends fast + slow signals
- **Kalman Filter** uses a probabilistic model to estimate angle + gyro bias

This project:

âœ” Generates synthetic robot motion  
âœ” Simulates sensor noise realistically  
âœ” Applies both filters  
âœ” Plots and compares their performance  
âœ” Computes RMSE (error)  

---

## ðŸ§  System Model

We estimate:

- **Î¸** (robot orientation)
- **b** (gyro bias)

State vector:

